1 - Implementing K-means
The K-means algorithm is a method to automatically cluster similar data points together.

Concretely, you are given a training set  {ğ‘¥(1),...,ğ‘¥(ğ‘š)} , and you want to group the data into a few cohesive â€œclustersâ€.
K-means is an iterative procedure that
Starts by guessing the initial centroids, and then
Refines this guess by
Repeatedly assigning examples to their closest centroids, and then
Recomputing the centroids based on the assignments.
In pseudocode, the K-means algorithm is as follows:

  # Initialize centroids
  # K is the number of clusters
  centroids = kMeans_init_centroids(X, K)

  for iter in range(iterations):
      # Cluster assignment step: 
      # Assign each data point to the closest centroid. 
      # idx[i] corresponds to the index of the centroid 
      # assigned to example i
      idx = find_closest_centroids(X, centroids)

      # Move centroid step: 
      # Compute means based on centroid assignments
      centroids = compute_centroids(X, idx, K)
The inner-loop of the algorithm repeatedly carries out two steps:
Assigning each training example  ğ‘¥(ğ‘–)  to its closest centroid, and
Recomputing the mean of each centroid using the points assigned to it.
The  ğ¾ -means algorithm will always converge to some final set of means for the centroids.

However, the converged solution may not always be ideal and depends on the initial setting of the centroids.

Therefore, in practice the K-means algorithm is usually run a few times with different random initializations.
One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function value (distortion).
You will implement the two phases of the K-means algorithm separately in the next sections.

You will start by completing find_closest_centroid and then proceed to complete compute_centroids.

1.1 Finding closest centroids
In the â€œcluster assignmentâ€ phase of the K-means algorithm, the algorithm assigns every training example ğ‘¥(ğ‘–) to its closest centroid, given the current positions of centroids.


Exercise 1
Your task is to complete the code in find_closest_centroids.

This function takes the data matrix X and the locations of all centroids inside centroids
It should output a one-dimensional array idx (which has the same number of elements as X) that holds the index of the closest centroid (a value in {1,...,ğ¾}, where ğ¾ is total number of centroids) to every training example .
Specifically, for every example ğ‘¥(ğ‘–) we set
ğ‘(ğ‘–):=ğ‘—thatminimizes||ğ‘¥(ğ‘–)âˆ’ğœ‡ğ‘—||2,
where
ğ‘(ğ‘–) is the index of the centroid that is closest to ğ‘¥(ğ‘–) (corresponds to idx[i] in the starter code), and
ğœ‡ğ‘— is the position (value) of the ğ‘—â€™th centroid. (stored in centroids in the starter code)
If you get stuck, you can check out the hints presented after the cell below to help you with the implementation.

# UNQ_C1
# GRADED FUNCTION: find_closest_centroids
â€‹
def find_closest_centroids(X, centroids):
    """
    Computes the centroid memberships for every example
    
    Args:
        X (ndarray): (m, n) Input values      
        centroids (ndarray): k centroids
    
    Returns:
        idx (array_like): (m,) closest centroids
    
    """
â€‹
    # Set K
    K = centroids.shape[0]
â€‹
    # You need to return the following variables correctly
    idx = np.zeros(X.shape[0], dtype=int)
â€‹
    ### START CODE HERE ###
    for i in range(X.shape[0]):
          # Array to hold distance between X[i] and each centroids[j]
          distance = [] 
          for j in range(centroids.shape[0]):
              norm_ij = np.linalg.norm(X[i] - centroids[j]) 
              distance.append(norm_ij)
â€‹
          idx[i] = np.argmin(distance)
    ### END CODE HERE ###
    
    return idx
    
    1.2 Computing centroid means
Given assignments of every point to a centroid, the second phase of the algorithm recomputes, for each centroid, the mean of the points that were assigned to it.


Exercise 2
Please complete the compute_centroids below to recompute the value for each centroid

Specifically, for every centroid  ğœ‡ğ‘˜  we set
ğœ‡ğ‘˜=1|ğ¶ğ‘˜|âˆ‘ğ‘–âˆˆğ¶ğ‘˜ğ‘¥(ğ‘–)
 
where

ğ¶ğ‘˜  is the set of examples that are assigned to centroid  ğ‘˜ 
|ğ¶ğ‘˜|  is the number of examples in the set  ğ¶ğ‘˜ 
Concretely, if two examples say  ğ‘¥(3)  and  ğ‘¥(5)  are assigned to centroid  ğ‘˜=2 , then you should update  ğœ‡2=12(ğ‘¥(3)+ğ‘¥(5)) .
If you get stuck, you can check out the hints presented after the cell below to help you with the implementation.

# UNQ_C2
# GRADED FUNCTION: compute_centpods
â€‹
def compute_centroids(X, idx, K):
    """
    Returns the new centroids by computing the means of the 
    data points assigned to each centroid.
    
    Args:
        X (ndarray):   (m, n) Data points
        idx (ndarray): (m,) Array containing index of closest centroid for each 
                       example in X. Concretely, idx[i] contains the index of 
                       the centroid closest to example i
        K (int):       number of centroids
    
    Returns:
        centroids (ndarray): (K, n) New centroids computed
    """
    
    # Useful variables
    m, n = X.shape
    
    # You need to return the following variables correctly
    centroids = np.zeros((K, n))
    
    ### START CODE HERE ###
    for k in range(K):   
          points = X[idx == k]  # Your code here to get a list of all data points in X assigned to centroid k  
          centroids[k] = np.mean(points, axis = 0)# Your code here to compute the mean of the points assigned
  
    ### END CODE HERE ## 
    
    return centroids
    
    K = 3
centroids = compute_centroids(X, idx, K)

print("The centroids are:", centroids)

# UNIT TEST
compute_centroids_test(compute_centroids)

# You do not need to implement anything for this part

def run_kMeans(X, initial_centroids, max_iters=10, plot_progress=False):
    """
    Runs the K-Means algorithm on data matrix X, where each row of X
    is a single example
    """
    
    # Initialize values
    m, n = X.shape
    K = initial_centroids.shape[0]
    centroids = initial_centroids
    previous_centroids = centroids    
    idx = np.zeros(m)
    
    # Run K-Means
    for i in range(max_iters):
        
        #Output progress
        print("K-Means iteration %d/%d" % (i, max_iters-1))
        
        # For each example in X, assign it to the closest centroid
        idx = find_closest_centroids(X, centroids)
        
        # Optionally plot progress
        if plot_progress:
            plot_progress_kMeans(X, centroids, previous_centroids, idx, K, i)
            previous_centroids = centroids
            
        # Given the memberships, compute new centroids
        centroids = compute_centroids(X, idx, K)
    plt.show() 
    return centroids, idx
    
    # Load an example dataset
X = load_data()

# Set initial centroids
initial_centroids = np.array([[3,3],[6,2],[8,5]])
K = 3

# Number of iterations
max_iters = 10

centroids, idx = run_kMeans(X, initial_centroids, max_iters, plot_progress=True)

3 - Random initialization
The initial assignments of centroids for the example dataset was designed so that you will see the same figure as in Figure 1. In practice, a good strategy for initializing the centroids is to select random examples from the training set.

In this part of the exercise, you should understand how the function kMeans_init_centroids is implemented.

The code first randomly shuffles the indices of the examples (using np.random.permutation()).
Then, it selects the first  ğ¾  examples based on the random permutation of the indices.
This allows the examples to be selected at random without the risk of selecting the same example twice.
Note: You do not need to implement anything for this part of the exercise.

# You do not need to modify this part
â€‹
def kMeans_init_centroids(X, K):
    """
    This function initializes K centroids that are to be 
    used in K-Means on the dataset X
    
    Args:
        X (ndarray): Data points 
        K (int):     number of centroids/clusters
    
    Returns:
        centroids (ndarray): Initialized centroids
    """
    
    # Randomly reorder the indices of examples
    randidx = np.random.permutation(X.shape[0])
    
    # Take the first K examples as centroids
    centroids = X[randidx[:K]]
    
    return centroids
    
    
